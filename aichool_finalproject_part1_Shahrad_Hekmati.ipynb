{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define paths and read date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahr\\AppData\\Local\\Temp\\ipykernel_10940\\2507964604.py:58: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data is expected to be in format `x`, `(x,)`, `(x, y)`, or `(x, y, sample_weight)`, found: (<keras.src.preprocessing.image.DirectoryIterator object at 0x000002B6EFC43AD0>, <keras.src.preprocessing.image.DirectoryIterator object at 0x000002B6DB52D310>, <keras.src.preprocessing.image.DirectoryIterator object at 0x000002B68221B450>, <keras.src.preprocessing.image.DirectoryIterator object at 0x000002B6821F8190>, <keras.src.preprocessing.image.DirectoryIterator object at 0x000002B689245050>, <keras.src.preprocessing.image.DirectoryIterator object at 0x000002B689451B10>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 58\u001b[0m\n\u001b[0;32m     55\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m model\u001b[38;5;241m.\u001b[39mfit_generator(\n\u001b[0;32m     59\u001b[0m     train_generators,\n\u001b[0;32m     60\u001b[0m     steps_per_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m,\n\u001b[0;32m     61\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     62\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_generators,\n\u001b[0;32m     63\u001b[0m     validation_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m\n\u001b[0;32m     64\u001b[0m )\n",
      "File \u001b[1;32md:\\programs\\Anaconda\\Lib\\site-packages\\keras\\src\\engine\\training.py:2913\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2901\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   2902\u001b[0m \n\u001b[0;32m   2903\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   2904\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[0;32m   2905\u001b[0m \u001b[38;5;124;03m  use this endpoint.\u001b[39;00m\n\u001b[0;32m   2906\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2907\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2908\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2909\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2910\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2911\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   2912\u001b[0m )\n\u001b[1;32m-> 2913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m   2914\u001b[0m     generator,\n\u001b[0;32m   2915\u001b[0m     steps_per_epoch\u001b[38;5;241m=\u001b[39msteps_per_epoch,\n\u001b[0;32m   2916\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[0;32m   2917\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   2918\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m   2919\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_data,\n\u001b[0;32m   2920\u001b[0m     validation_steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[0;32m   2921\u001b[0m     validation_freq\u001b[38;5;241m=\u001b[39mvalidation_freq,\n\u001b[0;32m   2922\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39mclass_weight,\n\u001b[0;32m   2923\u001b[0m     max_queue_size\u001b[38;5;241m=\u001b[39mmax_queue_size,\n\u001b[0;32m   2924\u001b[0m     workers\u001b[38;5;241m=\u001b[39mworkers,\n\u001b[0;32m   2925\u001b[0m     use_multiprocessing\u001b[38;5;241m=\u001b[39muse_multiprocessing,\n\u001b[0;32m   2926\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[0;32m   2927\u001b[0m     initial_epoch\u001b[38;5;241m=\u001b[39minitial_epoch,\n\u001b[0;32m   2928\u001b[0m )\n",
      "File \u001b[1;32md:\\programs\\Anaconda\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\programs\\Anaconda\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1883\u001b[0m, in \u001b[0;36munpack_x_y_sample_weight\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1878\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1879\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1880\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData is expected to be in format `x`, `(x,)`, `(x, y)`, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1881\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `(x, y, sample_weight)`, found: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1882\u001b[0m     )\u001b[38;5;241m.\u001b[39mformat(data)\n\u001b[1;32m-> 1883\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data is expected to be in format `x`, `(x,)`, `(x, y)`, or `(x, y, sample_weight)`, found: (<keras.src.preprocessing.image.DirectoryIterator object at 0x000002B6EFC43AD0>, <keras.src.preprocessing.image.DirectoryIterator object at 0x000002B6DB52D310>, <keras.src.preprocessing.image.DirectoryIterator object at 0x000002B68221B450>, <keras.src.preprocessing.image.DirectoryIterator object at 0x000002B6821F8190>, <keras.src.preprocessing.image.DirectoryIterator object at 0x000002B689245050>, <keras.src.preprocessing.image.DirectoryIterator object at 0x000002B689451B10>)"
     ]
    }
   ],
   "source": [
    "# Get the absolute path of the current directory\n",
    "base_dir = os.path.abspath('.')\n",
    "\n",
    "# Join the base directory with the relative path of the directories\n",
    "cardboard_dir = os.path.join(base_dir, 'TrashType_Image_Dataset', 'cardboard')\n",
    "glass_dir = os.path.join(base_dir, 'TrashType_Image_Dataset', 'glass')\n",
    "metal_dir = os.path.join(base_dir, 'TrashType_Image_Dataset', 'metal')\n",
    "paper_dir = os.path.join(base_dir, 'TrashType_Image_Dataset', 'paper')\n",
    "plastic_dir = os.path.join(base_dir, 'TrashType_Image_Dataset', 'plastic')\n",
    "trash_dir = os.path.join(base_dir, 'TrashType_Image_Dataset', 'trash')\n",
    "\n",
    "# Define the paths to the directories\n",
    "paths = [cardboard_dir, glass_dir, metal_dir, paper_dir, plastic_dir, trash_dir]\n",
    "\n",
    "# Define data augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Function to load images from directory and apply data augmentation\n",
    "def load_images_from_directory(directory, batch_size=32):\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    return generator\n",
    "\n",
    "# Load augmented images for training and validation\n",
    "train_generators, validation_generators = [], []\n",
    "for path in paths:\n",
    "    train_generator = load_images_from_directory(path, batch_size=32)\n",
    "    validation_generator = load_images_from_directory(path, batch_size=32)\n",
    "    x, y = train_generator.next()\n",
    "    validation_x, validation_y = validation_generator.next()\n",
    "    train_generators.append((x, y))\n",
    "    validation_generators.append((validation_x, validation_y))\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit_generator(\n",
    "    train_generators,\n",
    "    steps_per_epoch=2000,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generators,\n",
    "    validation_steps=800\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
